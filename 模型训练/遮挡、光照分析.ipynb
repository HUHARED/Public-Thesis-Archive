{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "\"\"\" 我应当做的是分别加载遮挡&光照不同情况的文件夹，手动删掉空文件夹，将剩余文件夹的文件夹名、图片数量，识别率保存到List，在保存到DF，CSV \"\"\"\n",
    "path=r\"./images/遮挡&光照/后腿遮挡/\"\n",
    "temp=os.listdir(path)\n",
    "dirPath=[]\n",
    "for i in range(len(temp)):\n",
    "    dirPath.append(path+temp[i]+\"/\")\n",
    "\"\"\" 保存好对应不同品种文件夹的路径后，创建DF \"\"\"\n",
    "dfResult=pd.DataFrame(columns=[\"breedName\",\"path\", \"imagesNumber\",\"predsRate\"])\n",
    "dfResult[\"breedName\"]=temp\n",
    "dfResult[\"path\"]=dirPath\n",
    "\"\"\" 统计不同文件夹的文件数量 \"\"\"\n",
    "seek=0\n",
    "for ele in dirPath:\n",
    "    count=0\n",
    "    for root,dirs,files in os.walk(ele):\n",
    "        for file in files:\n",
    "            count+=1\n",
    "    dfResult.at[seek,\"imagesNumber\"]=count\n",
    "    seek+=1\n",
    "\"\"\" 接下来是计算不同种类的识别率 \"\"\"\n",
    "nowClassToIndex = {\n",
    "    x: i for i, x in enumerate(temp)\n",
    "}\n",
    "\"\"\"\n",
    "IndexToClass = {\n",
    "    i: x for i, x in enumerate(temp)\n",
    "}\n",
    " \"\"\"\n",
    "dfAllFilePath = pd.read_csv(\"./all_image_path.csv\")\n",
    "classToIndex = {\n",
    "    x: i for i, x in enumerate(dfAllFilePath[\"breed\"].unique())\n",
    "}\n",
    "indexToClass = {\n",
    "    i: x for i, x in enumerate(dfAllFilePath[\"breed\"].unique())\n",
    "}\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "imageTransform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "model=torch.load(\"./test4_resnet_epochnumber_30.pkl\")\n",
    "model.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 遍历每个文件夹，构建每个文件的路径，按照路径加载图像，传入网络，如果索引对应的名称等于文件夹名称，预测正确数+1，然后预测正确数除以文件夹图片总数，得出识别率，识别率填入DF \"\"\"\n",
    "for ele in dirPath:\n",
    "    breedName=ele.split(\"/\")[-2]\n",
    "    label=classToIndex.get(breedName)\n",
    "    corrects=0\n",
    "    for root,dirs,files in os.walk(ele):\n",
    "        for file in files:\n",
    "            imagePath=ele+file\n",
    "            # print(imagePath)\n",
    "            image=Image.open(imagePath)\n",
    "            if image.mode !=\"RGB\":\n",
    "                image = image.convert(\"RGB\")\n",
    "            image=imageTransform(image)\n",
    "            image=torch.unsqueeze(image,0)\n",
    "            image=image.float().cuda()\n",
    "            output=model(image)\n",
    "            _, preds = torch.max(output.data, dim=1)\n",
    "            preds=preds.item()\n",
    "            \"\"\" if breedName==\"Dilute Calico\":\n",
    "                predsBreed=indexToClass.get(preds)\n",
    "                print(predsBreed) \"\"\"\n",
    "            \n",
    "            if label==preds:\n",
    "                corrects+=1\n",
    "    index=nowClassToIndex.get(breedName)\n",
    "    # print(index)\n",
    "    imagesNumber=dfResult.at[index,\"imagesNumber\"]\n",
    "    # print(imagesNumber)\n",
    "    predsRate=corrects/imagesNumber\n",
    "    predsRate=round(predsRate,2)\n",
    "    dfResult.at[index,\"predsRate\"]=predsRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResult.to_csv(path+\"结果.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 遮挡文件夹已经划分好，构建每个图片的路径、品种 \"\"\"\n",
    "#统计不同文件夹下文件的个数\n",
    "path=r\"./images/test_dateset/\"\n",
    "temp=os.listdir(path)\n",
    "dfBase=pd.DataFrame(temp)\n",
    "dfBase=dfBase.rename(columns={0:\"breed\"})\n",
    "dfBase[\"dir\"]=\"\"\n",
    "dfBase[\"count\"]=0\n",
    "#填入不同文件夹的路径\n",
    "seek=0\n",
    "for root,dirs,files in os.walk(path):\n",
    "    for ele in dirs:\n",
    "        dfBase.loc[seek,\"dir\"]=os.path.join(path,ele)\n",
    "        seek+=1\n",
    "#遍历不同文件夹，计算不同文件夹下的图片文件数量\n",
    "seek=0\n",
    "for ele in dfBase[\"dir\"]:\n",
    "    count=0\n",
    "    for root,dirs,files in os.walk(ele):\n",
    "        for file in files:\n",
    "            count+=1\n",
    "    dfBase.loc[seek,\"count\"]=count\n",
    "    seek+=1\n",
    "#将初步统计结果保存\n",
    "dfBase.to_csv(\"./遮挡文件路径.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" 这部分已经完成 \"\"\"\n",
    "# dfAllFilePath = pd.read_csv(\"./all_image_path.csv\")\n",
    "# imageFilesList = dfAllFilePath[\"breed\"].tolist()\n",
    "# classToIndex = {\n",
    "#     x: i for i, x in enumerate(dfAllFilePath[\"breed\"].unique())\n",
    "# }\n",
    "# IndexToClass = {\n",
    "#     i: x for i, x in enumerate(dfAllFilePath[\"breed\"].unique())\n",
    "# }\n",
    "# normalize = transforms.Normalize(\n",
    "#     mean=[0.485, 0.456, 0.406],\n",
    "#     std=[0.229, 0.224, 0.225]\n",
    "# )\n",
    "\n",
    "# dsTransforms = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     normalize\n",
    "# ])\n",
    "# # 由于数据集不同种类图片数量相差太大，所以训练、验证、测试集的划分要按照不同品种来划分\n",
    "# \"\"\"\n",
    "# 首先把40个不同品种的所有路径、品种分别保存到40个DataFrame中。然后40个DataFrame放到1个List中。\n",
    "# 由于之前统计过不同种类的图片数量，所以直接用数量来对大DataFrame切片\n",
    "# \"\"\"\n",
    "\n",
    "# breedsList = list(IndexToClass.values())\n",
    "# dfBreedsNumber = pd.read_csv(\"./breeds_number.csv\")\n",
    "# dfBreedsDict = {}\n",
    "# begin = 0\n",
    "# end = 0\n",
    "# for i in range(len(dfBreedsNumber)):\n",
    "#     breedName = dfBreedsNumber.iat[i, 0]\n",
    "#     end = dfBreedsNumber.iat[i, 2]+end\n",
    "#     tempDf = dfAllFilePath[begin:end]\n",
    "#     dfBreedsDict[breedName] = tempDf\n",
    "#     begin = end\n",
    "\n",
    "# # 用于存储53个品种的文件地址链接的字典已经创建完成，接下来就分别划分训练、验证、测试集，然后添加到分别添加到大的训练、验证、测试集中\n",
    "# dfTrain = pd.DataFrame(columns=[\"path\", \"breed\"])\n",
    "# dfValidate = dfTrain.copy()\n",
    "# dfTest = dfTrain.copy()\n",
    "# for ele in list(dfBreedsDict.keys()):\n",
    "#     # ele是DataFrame\n",
    "#     tempDf = dfBreedsDict[ele]\n",
    "#     tempTrain, tempValidate, tempTest = np.split(\n",
    "#         tempDf.sample(frac=1, random_state=42),\n",
    "#         [\n",
    "#             int(0.6*len(tempDf)),\n",
    "#             int(0.8*len(tempDf)),\n",
    "#         ]\n",
    "#     )\n",
    "#     dfTrain = dfTrain.append(tempTrain, ignore_index=True)\n",
    "#     dfValidate = dfValidate.append(tempValidate, ignore_index=True)\n",
    "#     dfTest = dfTest.append(tempTest, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# \"\"\" 测试集以及划分出来了，接下来更改路径为本地文件路径（原本是服务器路径），然后复制到品种对应的文件夹  \"\"\"\n",
    "# # dfTest[\"moveTo\"]=None\n",
    "# testDatasetPath=r\"./images/test_dateset/\"\n",
    "# for seek in range(len(dfTest)):\n",
    "#     temp=dfTest.iat[seek,0]\n",
    "#     # break\n",
    "#     temp=temp.replace(r\"/raid/hjy/\",r\"./images/\")\n",
    "#     # dfTest.iat[seek,1]=temp\n",
    "#     # prefix,suffix=temp.split(\".\")\n",
    "#     copyPath=testDatasetPath+dfTest.iat[seek,1]+\"/\"\n",
    "#     shutil.copy(temp,copyPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}